{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51bc6172-0a57-4dd3-981e-fdd4b6b21dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e78a6a1-f691-43c9-9415-a53fa56cc86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: multi-qa-MiniLM-L6-cos-v1\n",
      "Model loaded in 2.73 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Load SBERT model\n",
    "model_name = \"multi-qa-MiniLM-L6-cos-v1\"\n",
    "print(f\"Loading model: {model_name}\")\n",
    "start_time = time.time()\n",
    "model = SentenceTransformer(model_name)\n",
    "load_time = time.time() - start_time\n",
    "print(f\"Model loaded in {load_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c68779a-abc8-4f84-a062-e1f0b46d7b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "PATH_COLLECTION_DATA = 'subtask4b_collection_data.pkl'\n",
    "\n",
    "df_collection = pd.read_pickle(PATH_COLLECTION_DATA)\n",
    "\n",
    "PATH_QUERY_TRAIN_DATA = 'subtask4b_query_tweets_train.tsv'\n",
    "PATH_QUERY_DEV_DATA = 'subtask4b_query_tweets_dev.tsv'\n",
    "\n",
    "df_query_train = pd.read_csv(PATH_QUERY_TRAIN_DATA, sep = '\\t')\n",
    "df_query_dev = pd.read_csv(PATH_QUERY_DEV_DATA, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f86a39d-79eb-4239-a876-89db10dc8cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding documents...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dec0a3b32254b7ba24069a811e798fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document encoding time: 1761.70 seconds\n"
     ]
    }
   ],
   "source": [
    "# Encode documents\n",
    "print(\"Encoding documents...\")\n",
    "start = time.time()\n",
    "df_collection['full_text'] = df_collection['title'].fillna('') + \" \" + df_collection['abstract'].fillna('')\n",
    "doc_embeddings = model.encode(df_collection['full_text'].tolist(), show_progress_bar=True, convert_to_tensor=True)\n",
    "doc_encoding_time = time.time() - start\n",
    "print(f\"Document encoding time: {doc_encoding_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7366566-0653-4145-9387-e83ce24a3a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding tweets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4345223875743a9a32171c5e67444ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet encoding time: 183.12 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Encoding tweets...\")\n",
    "start = time.time()\n",
    "tweet_embeddings = model.encode(df_query_dev['tweet_text'].tolist(), convert_to_tensor=True, show_progress_bar=True)\n",
    "tweet_encoding_time = time.time() - start\n",
    "print(f\"Tweet encoding time: {tweet_encoding_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e4258cc-c0c0-42b6-af94-17e23758a336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1400/1400 [00:28<00:00, 48.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# Similarity & Top-5 Predictions\n",
    "import torch\n",
    "\n",
    "predictions = []\n",
    "\n",
    "tweet_texts = df_query_dev['tweet_text'].tolist()\n",
    "tweet_ids = df_query_dev['post_id'].tolist()\n",
    "true_labels = df_query_dev['cord_uid'].tolist()\n",
    "\n",
    "doc_texts = df_collection['full_text'].tolist()\n",
    "doc_uids = df_collection['cord_uid'].tolist()\n",
    "\n",
    "for i in tqdm(range(len(tweet_embeddings))):\n",
    "    tweet_vec = tweet_embeddings[i]\n",
    "    cosine_scores = util.cos_sim(tweet_vec, doc_embeddings)[0]\n",
    "    top_results = torch.topk(cosine_scores, k=5)\n",
    "    top_indices = top_results.indices.tolist()\n",
    "    top_cord_uids = [doc_uids[idx] for idx in top_indices]\n",
    "\n",
    "    predictions.append({\n",
    "        'post_id': tweet_ids[i],\n",
    "        'tweet_text': tweet_texts[i],\n",
    "        'true': true_labels[i],\n",
    "        'preds': top_cord_uids\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e14bb78-ef27-49e3-9259-fd1bbc6e313c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5 for multi-qa-MiniLM-L6-cos-v1: 0.4938\n"
     ]
    }
   ],
   "source": [
    "# MRR@5 Evaluation\n",
    "def mrr_at_k(predictions, k=5):\n",
    "    total_mrr = 0\n",
    "    for pred in predictions:\n",
    "        if pred['true'] in pred['preds']:\n",
    "            rank = pred['preds'].index(pred['true']) + 1\n",
    "            total_mrr += 1 / rank\n",
    "    return total_mrr / len(predictions)\n",
    "\n",
    "mrr5 = mrr_at_k(predictions, k=5)\n",
    "print(f\"MRR@5 for multi-qa-MiniLM-L6-cos-v1: {mrr5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "932140a4-1aa1-4238-8ae1-23b3a8a16e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame()\n",
    "df_out['post_id'] = [p['post_id'] for p in predictions]\n",
    "df_out['preds'] = [str(p['preds']) for p in predictions]\n",
    "\n",
    "df_out.to_csv('predictions_multi-qa-MiniLM-L6-cos-v1.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ef02dfc-dffd-4052-b212-01e201e5c85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short tweet count: 32\n",
      "MRR@5 on short tweets: 0.2859375\n",
      "Accuracy (hit in top-5): 0.4375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>true</th>\n",
       "      <th>preds</th>\n",
       "      <th>hit_in_top5</th>\n",
       "      <th>mrr@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1119</td>\n",
       "      <td>it doesn't stop it. it reduces the risk of it....</td>\n",
       "      <td>w0ebmg16</td>\n",
       "      <td>[5i35zdmv, rmho6pur, lehzj4d8, 2fryixdh, hl956...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1229</td>\n",
       "      <td>How can indoor spread of COVID-19 through the ...</td>\n",
       "      <td>od5nnxvg</td>\n",
       "      <td>[aawjla6h, od5nnxvg, 5zn5mgi9, 4p6fcy8f, pc2cn...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2132</td>\n",
       "      <td>Lives lost to covid-19 in 81 countries  #ovhea...</td>\n",
       "      <td>6a728le9</td>\n",
       "      <td>[pn516wom, 1blzi9r3, n39y3kq2, 7omyaap8, nj94r...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2492</td>\n",
       "      <td>Hospital admission rate is 10x higher in unvac...</td>\n",
       "      <td>rpjg4a9i</td>\n",
       "      <td>[z1y1zgo8, snk26ii3, k2zrdjyo, 6ukt0gbn, cfd1x...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>2719</td>\n",
       "      <td>Vitamins and risk of COVID-19</td>\n",
       "      <td>ikon1ktb</td>\n",
       "      <td>[ikon1ktb, gg5c8v7d, m22h669g, lgtpeqhw, ncfvl...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>3071</td>\n",
       "      <td>Death from COVID-19 isn't the only issue. Brai...</td>\n",
       "      <td>dogsza0f</td>\n",
       "      <td>[3q3ywthu, ag6lu4em, 7xt894vr, 25aj8rj5, 6mfd3...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>3491</td>\n",
       "      <td>Bile salts in gut and liver pathophysiology</td>\n",
       "      <td>mlozjg9h</td>\n",
       "      <td>[mlozjg9h, 4evznllv, 306381wy, r9datawi, k0f4c...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>3874</td>\n",
       "      <td>the vaccine can worsen covid.... why would you...</td>\n",
       "      <td>rb20ge7e</td>\n",
       "      <td>[tcby6780, urv9o2f1, vw9jd88a, 72jwlfqr, 7hpor...</td>\n",
       "      <td>False</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>4218</td>\n",
       "      <td>Masks function.  Vaccines function.  Your refu...</td>\n",
       "      <td>1s8jzzwg</td>\n",
       "      <td>[qi1henyy, u8mu4yga, t0iw2vod, 1s8jzzwg, w1bx4...</td>\n",
       "      <td>True</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>4894</td>\n",
       "      <td>human IgG neutralizing monoclonal antibodies b...</td>\n",
       "      <td>ypls4zau</td>\n",
       "      <td>[ypls4zau, obhm5mc5, 91ea40nz, nc2sh98g, wq0me...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id                                         tweet_text      true  \\\n",
       "112     1119  it doesn't stop it. it reduces the risk of it....  w0ebmg16   \n",
       "126     1229  How can indoor spread of COVID-19 through the ...  od5nnxvg   \n",
       "210     2132  Lives lost to covid-19 in 81 countries  #ovhea...  6a728le9   \n",
       "249     2492  Hospital admission rate is 10x higher in unvac...  rpjg4a9i   \n",
       "271     2719                      Vitamins and risk of COVID-19  ikon1ktb   \n",
       "308     3071  Death from COVID-19 isn't the only issue. Brai...  dogsza0f   \n",
       "349     3491        Bile salts in gut and liver pathophysiology  mlozjg9h   \n",
       "385     3874  the vaccine can worsen covid.... why would you...  rb20ge7e   \n",
       "417     4218  Masks function.  Vaccines function.  Your refu...  1s8jzzwg   \n",
       "485     4894  human IgG neutralizing monoclonal antibodies b...  ypls4zau   \n",
       "\n",
       "                                                 preds  hit_in_top5  mrr@5  \n",
       "112  [5i35zdmv, rmho6pur, lehzj4d8, 2fryixdh, hl956...        False   0.00  \n",
       "126  [aawjla6h, od5nnxvg, 5zn5mgi9, 4p6fcy8f, pc2cn...         True   0.50  \n",
       "210  [pn516wom, 1blzi9r3, n39y3kq2, 7omyaap8, nj94r...        False   0.00  \n",
       "249  [z1y1zgo8, snk26ii3, k2zrdjyo, 6ukt0gbn, cfd1x...        False   0.00  \n",
       "271  [ikon1ktb, gg5c8v7d, m22h669g, lgtpeqhw, ncfvl...         True   1.00  \n",
       "308  [3q3ywthu, ag6lu4em, 7xt894vr, 25aj8rj5, 6mfd3...        False   0.00  \n",
       "349  [mlozjg9h, 4evznllv, 306381wy, r9datawi, k0f4c...         True   1.00  \n",
       "385  [tcby6780, urv9o2f1, vw9jd88a, 72jwlfqr, 7hpor...        False   0.00  \n",
       "417  [qi1henyy, u8mu4yga, t0iw2vod, 1s8jzzwg, w1bx4...         True   0.25  \n",
       "485  [ypls4zau, obhm5mc5, 91ea40nz, nc2sh98g, wq0me...         True   1.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds = pd.DataFrame(predictions)\n",
    "\n",
    "df_preds['length'] = df_preds['tweet_text'].str.len()\n",
    "short_tweets = df_preds[df_preds['length'] < 80].copy()\n",
    "\n",
    "def mrr_score(preds, true_label):\n",
    "    if true_label in preds:\n",
    "        return 1 / (preds.index(true_label) + 1)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "short_tweets['hit_in_top5'] = short_tweets.apply(lambda row: row['true'] in row['preds'], axis=1)\n",
    "short_tweets['mrr@5'] = short_tweets.apply(lambda row: mrr_score(row['preds'], row['true']), axis=1)\n",
    "\n",
    "print(\"Short tweet count:\", len(short_tweets))\n",
    "print(\"MRR@5 on short tweets:\", short_tweets['mrr@5'].mean())\n",
    "print(\"Accuracy (hit in top-5):\", short_tweets['hit_in_top5'].mean())\n",
    "\n",
    "short_tweets[['post_id', 'tweet_text', 'true', 'preds', 'hit_in_top5', 'mrr@5']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28275716-c713-48c5-93a9-b582178250d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct matches: 848\n",
      "Wrong matches: 552\n",
      "Sample Wrong Matches:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>top_5</th>\n",
       "      <th>true_cord_uid</th>\n",
       "      <th>similarity_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>IL-6 seems to be a primary catalyst of this un...</td>\n",
       "      <td>[zt5alyy2, vx9vqr1k, ozbmgd70, xh723tgl, 9l3x3...</td>\n",
       "      <td>8cvjsisw</td>\n",
       "      <td>[0.6958510875701904, 0.6509284973144531, 0.650...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>Significant vitamin D deficiency in people wit...</td>\n",
       "      <td>[gg5c8v7d, vbnke2q5, vzloj6b3, 0a1m1niu, tpmb3...</td>\n",
       "      <td>be8eu3qi</td>\n",
       "      <td>[0.8673973083496094, 0.8592214584350586, 0.854...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>158</td>\n",
       "      <td>The wearing of masks is associated with reduce...</td>\n",
       "      <td>[f96qs295, 1s8jzzwg, jjh1z5c6, umvrwgaw, w1bx4...</td>\n",
       "      <td>9b6cepf4</td>\n",
       "      <td>[0.6995384693145752, 0.6373393535614014, 0.623...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>169</td>\n",
       "      <td>Let's not forget our unheralded heroes?  peer-...</td>\n",
       "      <td>[edz3up3a, imheos0p, 78kbutc3, foy3dsq4, cfkh0...</td>\n",
       "      <td>z9vjo98p</td>\n",
       "      <td>[0.7646439075469971, 0.758554220199585, 0.7375...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173</td>\n",
       "      <td>Here's your proof, Hannah  betting on \"herd im...</td>\n",
       "      <td>[urv9o2f1, li5cw8xx, ztxfa5b8, o9me37ri, lbd6h...</td>\n",
       "      <td>q77tr31d</td>\n",
       "      <td>[0.6718001961708069, 0.6341763734817505, 0.632...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  \\\n",
       "0      116  IL-6 seems to be a primary catalyst of this un...   \n",
       "1      150  Significant vitamin D deficiency in people wit...   \n",
       "2      158  The wearing of masks is associated with reduce...   \n",
       "3      169  Let's not forget our unheralded heroes?  peer-...   \n",
       "4      173  Here's your proof, Hannah  betting on \"herd im...   \n",
       "\n",
       "                                               top_5 true_cord_uid  \\\n",
       "0  [zt5alyy2, vx9vqr1k, ozbmgd70, xh723tgl, 9l3x3...      8cvjsisw   \n",
       "1  [gg5c8v7d, vbnke2q5, vzloj6b3, 0a1m1niu, tpmb3...      be8eu3qi   \n",
       "2  [f96qs295, 1s8jzzwg, jjh1z5c6, umvrwgaw, w1bx4...      9b6cepf4   \n",
       "3  [edz3up3a, imheos0p, 78kbutc3, foy3dsq4, cfkh0...      z9vjo98p   \n",
       "4  [urv9o2f1, li5cw8xx, ztxfa5b8, o9me37ri, lbd6h...      q77tr31d   \n",
       "\n",
       "                                   similarity_scores  \n",
       "0  [0.6958510875701904, 0.6509284973144531, 0.650...  \n",
       "1  [0.8673973083496094, 0.8592214584350586, 0.854...  \n",
       "2  [0.6995384693145752, 0.6373393535614014, 0.623...  \n",
       "3  [0.7646439075469971, 0.758554220199585, 0.7375...  \n",
       "4  [0.6718001961708069, 0.6341763734817505, 0.632...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Correct Matches:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>top_5</th>\n",
       "      <th>true_cord_uid</th>\n",
       "      <th>similarity_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>[3qvh482o, 8t2tic9n, jrqlhjsm, rthsl7a9, trrg1...</td>\n",
       "      <td>3qvh482o</td>\n",
       "      <td>[0.732806921005249, 0.6959764957427979, 0.6864...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>\"Among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>[r58aohnu, atn333j9, d06npvro, a66sszp2, cpbu3...</td>\n",
       "      <td>r58aohnu</td>\n",
       "      <td>[0.7869398593902588, 0.7137505412101746, 0.651...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>I recall early on reading that researchers who...</td>\n",
       "      <td>[sts48u9i, qkg8fwbp, ujq9mxk7, dgizpo1z, ec6ov...</td>\n",
       "      <td>sts48u9i</td>\n",
       "      <td>[0.6247978210449219, 0.5791239738464355, 0.554...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>You know you're credible when NIH website has ...</td>\n",
       "      <td>[i03mrw1i, 6x33a6g6, hapu56t4, 3sr2exq9, f8yph...</td>\n",
       "      <td>3sr2exq9</td>\n",
       "      <td>[0.677467942237854, 0.6468799114227295, 0.6437...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>Resistance to antifungal medications is a grow...</td>\n",
       "      <td>[ybwwmyqy, ierqfgo5, vabb2f26, qh6rif48, fiicx...</td>\n",
       "      <td>ybwwmyqy</td>\n",
       "      <td>[0.7711814641952515, 0.6013863682746887, 0.572...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  \\\n",
       "0       16  covid recovery: this study from the usa reveal...   \n",
       "1       69  \"Among 139 clients exposed to two symptomatic ...   \n",
       "2       73  I recall early on reading that researchers who...   \n",
       "3       93  You know you're credible when NIH website has ...   \n",
       "4       96  Resistance to antifungal medications is a grow...   \n",
       "\n",
       "                                               top_5 true_cord_uid  \\\n",
       "0  [3qvh482o, 8t2tic9n, jrqlhjsm, rthsl7a9, trrg1...      3qvh482o   \n",
       "1  [r58aohnu, atn333j9, d06npvro, a66sszp2, cpbu3...      r58aohnu   \n",
       "2  [sts48u9i, qkg8fwbp, ujq9mxk7, dgizpo1z, ec6ov...      sts48u9i   \n",
       "3  [i03mrw1i, 6x33a6g6, hapu56t4, 3sr2exq9, f8yph...      3sr2exq9   \n",
       "4  [ybwwmyqy, ierqfgo5, vabb2f26, qh6rif48, fiicx...      ybwwmyqy   \n",
       "\n",
       "                                   similarity_scores  \n",
       "0  [0.732806921005249, 0.6959764957427979, 0.6864...  \n",
       "1  [0.7869398593902588, 0.7137505412101746, 0.651...  \n",
       "2  [0.6247978210449219, 0.5791239738464355, 0.554...  \n",
       "3  [0.677467942237854, 0.6468799114227295, 0.6437...  \n",
       "4  [0.7711814641952515, 0.6013863682746887, 0.572...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wrong_matches = []\n",
    "correct_matches = []\n",
    "for tweet_id, tweet_text, true_uid, tweet_emb in zip(tweet_ids, tweet_texts, true_labels, tweet_embeddings):\n",
    "    cosine_scores = util.cos_sim(tweet_emb, doc_embeddings)[0]\n",
    "\n",
    "    top_k = 5\n",
    "    top_results = torch.topk(cosine_scores, k=top_k)\n",
    "\n",
    "    top_indices = top_results.indices.tolist()\n",
    "    top_similarities = top_results.values.tolist()\n",
    "    top_cord_uids = [doc_uids[idx] for idx in top_indices]\n",
    "\n",
    "    result = {\n",
    "        'post_id': tweet_id,\n",
    "        'tweet_text': tweet_text,\n",
    "        'top_5': top_cord_uids,\n",
    "        'true_cord_uid': true_uid,\n",
    "        'similarity_scores': top_similarities\n",
    "    }\n",
    "\n",
    "    if true_uid in top_cord_uids:\n",
    "        correct_matches.append(result)\n",
    "    else:\n",
    "        wrong_matches.append(result)\n",
    "\n",
    "df_correct_matches = pd.DataFrame(correct_matches)\n",
    "df_wrong_matches = pd.DataFrame(wrong_matches)\n",
    "\n",
    "print(f\"Correct matches: {len(df_correct_matches)}\")\n",
    "print(f\"Wrong matches: {len(df_wrong_matches)}\")\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"Sample Wrong Matches:\")\n",
    "display(df_wrong_matches[['post_id', 'tweet_text', 'top_5', 'true_cord_uid', 'similarity_scores']].head())\n",
    "\n",
    "print(\"Sample Correct Matches:\")\n",
    "display(df_correct_matches[['post_id', 'tweet_text', 'top_5', 'true_cord_uid', 'similarity_scores']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35d02549-c720-45a2-a93a-9c16f93b63a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73fc8271f9024721ac05a29562236fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f555b7f61dca4572a8a52b1ce8422cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5 (score average): 0.5291\n"
     ]
    }
   ],
   "source": [
    "model_name2 = \"all-MiniLM-L6-v2\"\n",
    "model2 = SentenceTransformer(model_name2)\n",
    "doc_embeddings2 = model2.encode(df_collection['full_text'].tolist(), show_progress_bar=True, convert_to_tensor=True)\n",
    "tweet_embeddings2 = model2.encode(df_query_dev['tweet_text'].tolist(), convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "predictions = []\n",
    "k = 5\n",
    "\n",
    "for i in range(len(tweet_texts)):\n",
    "    tweet_id = tweet_ids[i]\n",
    "    tweet_text = tweet_texts[i]\n",
    "    true_uid = true_labels[i]\n",
    "\n",
    "    scores1 = util.cos_sim(tweet_embeddings[i], doc_embeddings)[0] #\"multi-qa-MiniLM-L6-cos-v1\"\n",
    "    scores2 = util.cos_sim(tweet_embeddings2[i], doc_embeddings2)[0] #\"all-MiniLM-L6-v2\"\n",
    "\n",
    "    avg_scores = (scores1 + scores2) / 2.0\n",
    "\n",
    "    top_k = torch.topk(avg_scores, k=k)\n",
    "    top_indices = top_k.indices.tolist()\n",
    "    top_cord_uids = [doc_uids[idx] for idx in top_indices]\n",
    "\n",
    "    predictions.append({\n",
    "        'post_id': tweet_id,\n",
    "        'true': true_uid,\n",
    "        'preds': top_cord_uids\n",
    "    })\n",
    "\n",
    "mrr_score = mrr_at_k(predictions, k=5)\n",
    "print(f\"MRR@{k} (score average): {mrr_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e0e09ea-2f4f-4678-8f80-4ddd696de672",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out_fasttext_crawl = pd.DataFrame()\n",
    "df_out_fasttext_crawl['post_id'] = [p['post_id'] for p in predictions]\n",
    "df_out_fasttext_crawl['preds'] = [str(p['preds']) for p in predictions]\n",
    "\n",
    "df_out_fasttext_crawl.to_csv('predictions_all-MiniLM_multi-qa.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d248796-c3e9-40f8-8363-7b725a6eee59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     35\u001b[39m train_loss = losses.TripletLoss(model=model)\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Modeli eğit\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_objectives\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     43\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m model.save(\u001b[33m'\u001b[39m\u001b[33mfine-tuned-multi-qa-MiniLM-L6-cos-v1\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     47\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mfine-tuned-multi-qa-MiniLM-L6-cos-v1\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/sentence_transformers/fit_mixin.py:278\u001b[39m, in \u001b[36mFitMixin.fit\u001b[39m\u001b[34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit, resume_from_checkpoint)\u001b[39m\n\u001b[32m    276\u001b[39m     texts += batch_texts\n\u001b[32m    277\u001b[39m     labels += batch_labels\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m dataset = \u001b[43mDataset\u001b[49m.from_dict({\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msentence_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m: text \u001b[38;5;28;01mfor\u001b[39;00m idx, text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(*texts))})\n\u001b[32m    279\u001b[39m \u001b[38;5;66;03m# Add label column, unless all labels are 0 (the default value for `labels` in InputExample)\u001b[39;00m\n\u001b[32m    280\u001b[39m add_label_column = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses, util\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "train_examples = []\n",
    "\n",
    "all_doc_ids = df_collection['cord_uid'].tolist()\n",
    "\n",
    "for idx, row in df_query_train.iterrows():\n",
    "    tweet = row['tweet_text']\n",
    "    pos_uid = row['cord_uid']\n",
    "\n",
    "    positive_doc = df_collection[df_collection['cord_uid'] == pos_uid]\n",
    "    if positive_doc.empty:\n",
    "        continue\n",
    "    pos_text = positive_doc.iloc[0]['title'] + \" \" + positive_doc.iloc[0]['abstract']\n",
    "\n",
    "    negative_uids = [uid for uid in all_doc_ids if uid != pos_uid]\n",
    "    neg_uid = random.choice(negative_uids)\n",
    "    negative_doc = df_collection[df_collection['cord_uid'] == neg_uid]\n",
    "    if negative_doc.empty:\n",
    "        continue\n",
    "    neg_text = negative_doc.iloc[0]['title'] + \" \" + negative_doc.iloc[0]['abstract']\n",
    "\n",
    "    train_examples.append(InputExample(texts=[tweet, pos_text, neg_text]))\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "train_loss = losses.TripletLoss(model=model)\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=3,\n",
    "    warmup_steps=100,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "model.save('fine-tuned-multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "model_name = \"fine-tuned-multi-qa-MiniLM-L6-cos-v1\"\n",
    "print(f\"Loading model: {model_name}\")\n",
    "start_time = time.time()\n",
    "model = SentenceTransformer(model_name)\n",
    "load_time = time.time() - start_time\n",
    "print(f\"Model loaded in {load_time:.2f} seconds.\")\n",
    "\n",
    "print(\"Encoding documents...\")\n",
    "start = time.time()\n",
    "df_collection['full_text'] = df_collection['title'].fillna('') + \" \" + df_collection['abstract'].fillna('')\n",
    "doc_embeddings = model.encode(df_collection['full_text'].tolist(), show_progress_bar=True, convert_to_tensor=True)\n",
    "doc_encoding_time = time.time() - start\n",
    "print(f\"Document encoding time: {doc_encoding_time:.2f} seconds\")\n",
    "\n",
    "print(\"Encoding tweets...\")\n",
    "start = time.time()\n",
    "tweet_embeddings = model.encode(df_query_dev['tweet_text'].tolist(), convert_to_tensor=True, show_progress_bar=True)\n",
    "tweet_encoding_time = time.time() - start\n",
    "print(f\"Tweet encoding time: {tweet_encoding_time:.2f} seconds\")\n",
    "\n",
    "predictions = []\n",
    "\n",
    "tweet_texts = df_query_dev['tweet_text'].tolist()\n",
    "tweet_ids = df_query_dev['post_id'].tolist()\n",
    "true_labels = df_query_dev['cord_uid'].tolist()\n",
    "\n",
    "doc_texts = df_collection['full_text'].tolist()\n",
    "doc_uids = df_collection['cord_uid'].tolist()\n",
    "\n",
    "for i in tqdm(range(len(tweet_embeddings))):\n",
    "    tweet_vec = tweet_embeddings[i]\n",
    "    cosine_scores = util.cos_sim(tweet_vec, doc_embeddings)[0]\n",
    "    top_results = torch.topk(cosine_scores, k=5)\n",
    "    top_indices = top_results.indices.tolist()\n",
    "    top_cord_uids = [doc_uids[idx] for idx in top_indices]\n",
    "\n",
    "    predictions.append({\n",
    "        'post_id': tweet_ids[i],\n",
    "        'tweet_text': tweet_texts[i],\n",
    "        'true': true_labels[i],\n",
    "        'preds': top_cord_uids\n",
    "    })\n",
    "\n",
    "def mrr_at_k(predictions, k=5):\n",
    "    total_mrr = 0\n",
    "    for pred in predictions:\n",
    "        if pred['true'] in pred['preds']:\n",
    "            rank = pred['preds'].index(pred['true']) + 1\n",
    "            total_mrr += 1 / rank\n",
    "    return total_mrr / len(predictions)\n",
    "\n",
    "mrr5 = mrr_at_k(predictions, k=5)\n",
    "print(f\"MRR@5 for fine-tuned-all-MiniLM-L6-v2: {mrr5:.4f}\")\n",
    "\n",
    "df_out = pd.DataFrame()\n",
    "df_out['post_id'] = [p['post_id'] for p in predictions]\n",
    "df_out['preds'] = [str(p['preds']) for p in predictions]\n",
    "\n",
    "df_out.to_csv('predictions_multi-qa-MiniLM-L6-cos-v1.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e0963d-bffe-4211-bf87-46713ee937eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
