{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efd1ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses, models,util\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from random import choice\n",
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "259bc4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 12853 training rows with random negatives.\n"
     ]
    }
   ],
   "source": [
    "# Build training data Basic Positive + Random Negative\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "\n",
    "# Load datasets\n",
    "df_queries = pd.read_csv(\"subtask4b_query_tweets_train.tsv\", sep=\"\\t\")\n",
    "df_cord = pd.read_pickle(\"subtask4b_collection_data.pkl\")\n",
    "\n",
    "# Build a dict of cord_uid â†’ abstract\n",
    "cord_abstract_map = dict(zip(df_cord['cord_uid'], df_cord['abstract']))\n",
    "\n",
    "# Clean out any queries with missing abstracts\n",
    "df_queries = df_queries[df_queries['cord_uid'].isin(cord_abstract_map)]\n",
    "\n",
    "\n",
    "train_rows = []\n",
    "\n",
    "all_uids = list(cord_abstract_map.keys())\n",
    "\n",
    "for _, row in df_queries.iterrows():\n",
    "    query = row['tweet_text']\n",
    "    pos_uid = row['cord_uid']\n",
    "    pos_abstract = cord_abstract_map[pos_uid]\n",
    "\n",
    "    # Sample a hard negative (non-matching abstract)\n",
    "    neg_uid = choice([uid for uid in all_uids if uid != pos_uid])\n",
    "    neg_abstract = cord_abstract_map[neg_uid]\n",
    "\n",
    "    train_rows.append({\n",
    "        \"tweet_text\": query,\n",
    "        \"pos_abstract\": pos_abstract,\n",
    "        \"neg_abstract\": neg_abstract\n",
    "    })\n",
    "\n",
    "df_train = pd.DataFrame(train_rows)\n",
    "df_train.to_csv(\"training_data.csv\", index=False)\n",
    "print(f\"Generated {len(df_train)} training rows with random negatives.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545520ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d7fbf3a4f34379a8e484874e903be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='4821' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  46/4821 00:18 < 32:33, 2.44 it/s, Epoch 0.03/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m     22\u001b[0m warmup_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_dataloader) \u001b[38;5;241m*\u001b[39m num_epochs \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_objectives\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfine-tuned-all-MiniLM-L6-v2_basic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     30\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\flori\\miniconda3\\envs\\py39\\lib\\site-packages\\sentence_transformers\\fit_mixin.py:408\u001b[0m, in \u001b[0;36mFitMixin.fit\u001b[1;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit, resume_from_checkpoint)\u001b[0m\n\u001b[0;32m    405\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheckpoint directory does not exist or is not a directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    406\u001b[0m         resume_from_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 408\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\flori\\miniconda3\\envs\\py39\\lib\\site-packages\\transformers\\trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\flori\\miniconda3\\envs\\py39\\lib\\site-packages\\transformers\\trainer.py:2562\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m   2560\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m-> 2562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2563\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2564\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2565\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2566\u001b[0m ):\n\u001b[0;32m   2567\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2568\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[0;32m   2569\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model = SentenceTransformer(\"multi-qa-MiniLM-L6-cos-v1\")\n",
    "# Load the training data\n",
    "df = pd.read_csv(\"training_data.csv\")\n",
    "\n",
    "# Format: query | positive_passage | hard_negative_passage\n",
    "train_examples = []\n",
    "for _, row in df.iterrows():\n",
    "    query = \"query: \" + row[\"tweet_text\"]\n",
    "    positive = \"passage: \" + row[\"pos_abstract\"]\n",
    "    negative = \"passage: \" + row[\"neg_abstract\"]\n",
    "    \n",
    "    train_examples.append(\n",
    "        InputExample(texts=[query, positive, negative])\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=32)\n",
    "\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
    "\n",
    "num_epochs = 3\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1)\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    show_progress_bar=True,\n",
    "    output_path=\"fine-tuned-multi-qa-MiniLM-L6-cos-v1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7657314c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d90f5e90b2f4746a16a573b0beeb84a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8598f92835848a29031ec74d36d6075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1400/1400 [00:00<00:00, 2125.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5 for multi-qa-MiniLM-L6-cos-v1: 0.6067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# MRR@5 Evaluation\n",
    "import torch\n",
    "\n",
    "model_name = \"fine-tuned-all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "PATH_COLLECTION_DATA = 'subtask4b_collection_data.pkl'\n",
    "\n",
    "df_collection = pd.read_pickle(PATH_COLLECTION_DATA)\n",
    "\n",
    "PATH_QUERY_TRAIN_DATA = 'subtask4b_query_tweets_train.tsv'\n",
    "PATH_QUERY_DEV_DATA = 'subtask4b_query_tweets_dev.tsv'\n",
    "\n",
    "df_query_train = pd.read_csv(PATH_QUERY_TRAIN_DATA, sep = '\\t')\n",
    "df_query_dev = pd.read_csv(PATH_QUERY_DEV_DATA, sep = '\\t')\n",
    "\n",
    "predictions = []\n",
    "df_collection['full_text'] = df_collection['title'].fillna('') + \" \" + df_collection['abstract'].fillna('')\n",
    "\n",
    "doc_embeddings = model.encode(df_collection['full_text'].tolist(), show_progress_bar=True, convert_to_tensor=True)\n",
    "tweet_embeddings = model.encode(df_query_dev['tweet_text'].tolist(), convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "\n",
    "tweet_texts = df_query_dev['tweet_text'].tolist()\n",
    "tweet_ids = df_query_dev['post_id'].tolist()\n",
    "true_labels = df_query_dev['cord_uid'].tolist()\n",
    "\n",
    "doc_texts = df_collection['full_text'].tolist()\n",
    "doc_uids = df_collection['cord_uid'].tolist()\n",
    "\n",
    "for i in tqdm(range(len(tweet_embeddings))):\n",
    "    tweet_vec = tweet_embeddings[i]\n",
    "    cosine_scores = util.cos_sim(tweet_vec, doc_embeddings)[0]\n",
    "    top_results = torch.topk(cosine_scores, k=5)\n",
    "    top_indices = top_results.indices.tolist()\n",
    "    top_cord_uids = [doc_uids[idx] for idx in top_indices]\n",
    "\n",
    "    predictions.append({\n",
    "        'post_id': tweet_ids[i],\n",
    "        'tweet_text': tweet_texts[i],\n",
    "        'true': true_labels[i],\n",
    "        'preds': top_cord_uids\n",
    "    })\n",
    "\n",
    "# MRR@5 Evaluation\n",
    "def mrr_at_k(predictions, k=5):\n",
    "    total_mrr = 0\n",
    "    for pred in predictions:\n",
    "        if pred['true'] in pred['preds']:\n",
    "            rank = pred['preds'].index(pred['true']) + 1\n",
    "            total_mrr += 1 / rank\n",
    "    return total_mrr / len(predictions)\n",
    "\n",
    "mrr5 = mrr_at_k(predictions, k=5)\n",
    "print(f\"MRR@5 for multi-qa-MiniLM-L6-cos-v1: {mrr5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17a01cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a87dc3ef33474fabfbb2e238a0ba98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bdc7f54f47b40f58d8cb094f4c7a41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5 (score average): 0.6071\n"
     ]
    }
   ],
   "source": [
    "# MRR@5 Evaluation for combined model\n",
    "model_name2 = \"fine-tuned-multi-qa-MiniLM-L6-cos-v1\"\n",
    "model2 = SentenceTransformer(model_name2)\n",
    "doc_embeddings2 = model2.encode(df_collection['full_text'].tolist(), show_progress_bar=True, convert_to_tensor=True)\n",
    "tweet_embeddings2 = model2.encode(df_query_dev['tweet_text'].tolist(), convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "predictions = []\n",
    "k = 5\n",
    "\n",
    "for i in range(len(tweet_texts)):\n",
    "    tweet_id = tweet_ids[i]\n",
    "    tweet_text = tweet_texts[i]\n",
    "    true_uid = true_labels[i]\n",
    "\n",
    "    scores1 = util.cos_sim(tweet_embeddings[i], doc_embeddings)[0] \n",
    "    scores2 = util.cos_sim(tweet_embeddings2[i], doc_embeddings2)[0]\n",
    "\n",
    "    avg_scores = (scores1 + scores2) / 2.0\n",
    "\n",
    "    top_k = torch.topk(avg_scores, k=k)\n",
    "    top_indices = top_k.indices.tolist()\n",
    "    top_cord_uids = [doc_uids[idx] for idx in top_indices]\n",
    "\n",
    "    predictions.append({\n",
    "        'post_id': tweet_id,\n",
    "        'true': true_uid,\n",
    "        'preds': top_cord_uids\n",
    "    })\n",
    "\n",
    "mrr_score = mrr_at_k(predictions, k=5)\n",
    "print(f\"MRR@{k} (score average): {mrr_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
